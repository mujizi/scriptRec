import os
import json
import gradio as gr
import pandas as pd
from typing import List, Dict, Any, Optional
import asyncio
from openai import AsyncAzureOpenAI
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv('/opt/rag_milvus_kb_project/.env')

# ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
AZURE_OPENAI_API_KEY = os.getenv('AZURE_OPENAI_API_KEY')
AZURE_OPENAI_ENDPOINT = os.getenv('AZURE_OPENAI_ENDPOINT')
API_VERSION = os.getenv('API_VERSION', '2024-02-15-preview')

if not all([AZURE_OPENAI_API_KEY, AZURE_OPENAI_ENDPOINT]):
    raise ValueError("Missing required environment variables: AZURE_OPENAI_API_KEY or AZURE_OPENAI_ENDPOINT")

SCRIPT_DIR = "/opt/Filmdataset/demo/clean"
OUTPUT_DIR = "/opt/Filmdataset/demo/character"
os.makedirs(OUTPUT_DIR, exist_ok=True)

# æç¤ºè¯å®šä¹‰ï¼ˆä¿æŒåŸæ ¼å¼ï¼‰
PROMPT = """
- systemæç¤ºè¯
    - ä½ æ˜¯ä¸€ä½ä¸“ä¸šç”µå½±ç¼–å‰§ã€‚
 - æ ¹æ®æ‰€ç»™å‰§æœ¬ï¼Œè·å–å‰§æœ¬åï¼ˆscript_nameï¼‰ï¼Œæ€»ç»“è¯¥ç”µå½±å‰§æœ¬çš„ä¸»è¦äººç‰©ä¿¡æ¯(åŒ…æ‹¬ä¸»è§’ã€åæ´¾ã€é‡è¦æ”¯æ’‘è§’è‰²ç­‰å¯¹æ•…äº‹æ¨åŠ¨å‘æŒ¥é‡è¦ä½œç”¨çš„è§’è‰²)ï¼ŒæŒ‰å¦‚ä¸‹å†…å®¹è¾“å‡ºã€‚
        - åŸºæœ¬ä¿¡æ¯ï¼ˆbasic_informationï¼‰ï¼šåŒ…å«å§“åã€æ€§åˆ«ã€å¹´é¾„ã€å¤–è²Œç‰¹å¾ã€èŒä¸šç­‰ä¿¡æ¯ï¼›ä»¥ä¸€å¥è¯æè¿°ï¼Œå­—æ•°50-100å­—ã€‚
        - è§’è‰²ç‰¹å¾ï¼ˆcharacteristicsï¼‰ï¼šæ€§æ ¼ç‰¹ç‚¹ã€ä¼˜ç‚¹ã€å¼±ç‚¹ã€æŠ€èƒ½ã€çˆ±å¥½ã€ææƒ§ç­‰ä¿¡æ¯ï¼›ä»¥ä¸€å¥è¯æè¿°ï¼Œå­—æ•°50-100å­—ã€‚
        - äººç‰©å°ä¼ ï¼ˆbiographyï¼‰ï¼šè§’è‰²åŠ¨æœºã€ç›®æ ‡ï¼Œä»¥åŠä»–é‡åˆ°çš„å¯¹æŠ—æ€§åŠ›é‡ï¼Œä»–å¦‚ä½•å¯¹æŠ—å†²çªï¼Œæœ€ç»ˆçš„è§£å†³ç­‰ã€‚ä»¥åŠæ•…äº‹å‘å±•è¿‡ç¨‹ä¸­ï¼Œè§’è‰²æ‰€ç»å†çš„å˜åŒ–ä¸å‘å±•è½¨è¿¹(å¿ƒç†ã€æƒ…æ„Ÿä»¥åŠè¡Œä¸ºçš„è½¬å˜)ã€‚ä»¥ä¸€å¥è¯æè¿°ï¼Œå­—æ•°50-100å­—ã€‚
        - äººç‰©æ‘˜è¦ï¼ˆcharacter_summaryï¼‰:å°†basic_informationã€characteristicsã€biographyä¸‰è€…ç»“åˆï¼Œå½¢æˆä¸€ä¸ªå®Œæ•´çš„è§’è‰²æ‘˜è¦ã€‚ä»¥ä¸€å¥è¯æè¿°ï¼Œå­—æ•°50-100å­—ã€‚
- è¾“å‡ºæ ·ä¾‹
    - [{"character_name":{
        "character_name":"XXX",
        "basic_information":"XXX",
        "characteristics":"XXX",
        "biography":"XXX",
        "character_summary":"XXX",
        "script_name":"XXX"
        },
        "character_name":{
        "character_name":"XXX",
        "basic_information":"XXX",
        "characteristics":"XXX",
        "biography":"XXX",
        "character_summary":"XXX",
        "script_name":"XXX"
        }
        ...,
        "character_name":{
        "character_name":"XXX",
        "basic_information":"XXX",
        "characteristics":"XXX",
        "biography":"XXX",
        "character_summary":"XXX",
        "script_name":"XXX"
        }
        ]
- è¾“å‡ºè¦æ±‚
   - 1ã€ä¸¥æ ¼æŒ‰ç…§è¾“å‡ºæ ·ä¾‹çš„JSONæ ¼å¼è¾“å‡ºï¼Œä¸è¦æ–°å¢æˆ–ä¿®æ”¹åˆ—è¡¨é‡Œjsoné‡Œçš„å­—æ®µã€‚
"""

# æ¨¡å‹è°ƒç”¨å‡½æ•°
async def async_model_gpt4o_infer(instruct_text: str, raw_text: str) -> str:
    """è°ƒç”¨Azure OpenAIçš„gpt-4o-miniæ¨¡å‹è¿›è¡Œæ¨ç†ï¼Œç¡®ä¿è¿”å›JSONæ ¼å¼"""
    text = f"{instruct_text} {raw_text}"
    print(f"Processing text block of length: {len(raw_text)}")
    client = AsyncAzureOpenAI(
        azure_endpoint=AZURE_OPENAI_ENDPOINT,
        api_key=AZURE_OPENAI_API_KEY,
        api_version=API_VERSION
    )
    response = await client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": text}],
        temperature=1,
        top_p=0.7,
        response_format={"type": "json_object"}  # å¼ºåˆ¶è¦æ±‚JSONæ ¼å¼å“åº”
    )
    return response.choices[0].message.content

# äººç‰©ä¿¡æ¯æå–å‡½æ•°
async def extract_character_information(prompt: str, script_path: str) -> Dict[str, Dict[str, Any]]:
    """æå–å•ä¸ªå‰§æœ¬çš„äººç‰©ä¿¡æ¯"""
    try:
        with open(script_path, 'r', encoding='utf-8') as file:
            script_content = file.read()
        
        script_name = os.path.basename(script_path)
        result_text = await async_model_gpt4o_infer(prompt, script_content)
        
        # è§£æJSONç»“æœ
        try:
            result_data = json.loads(result_text)
            characters = result_data if isinstance(result_data, list) else list(result_data.values())
        except json.JSONDecodeError as e:
            print(f"è§£æJSONå¤±è´¥: {e}ï¼Œæ–‡ä»¶è·¯å¾„: {script_path}")
            return {
                "è§£æé”™è¯¯": {
                    "script_name": script_name,
                    "character_name": "è§£æé”™è¯¯",
                    "basic_information": f"JSONè§£æå¤±è´¥: {str(e)}",
                    "characteristics": "",
                    "character_summary": "",
                    "biography": ""
                }
            }
        
        # å¤„ç†äººç‰©é‡å
        character_dict = {}
        for char in characters:
            if 'character_name' not in char:
                continue
            char["script_name"] = script_name
            name = char["character_name"]
            if name in character_dict:
                count = 1
                while f"{name}_{count}" in character_dict:
                    count += 1
                name = f"{name}_{count}"
            character_dict[name] = char
        
        return character_dict

    except Exception as e:
        print(f"å¤„ç†æ–‡ä»¶å¤±è´¥: {e}ï¼Œæ–‡ä»¶è·¯å¾„: {script_path}")
        script_name = os.path.basename(script_path)
        return {
            "å¤„ç†é”™è¯¯": {
                "script_name": script_name,
                "character_name": "å¤„ç†é”™è¯¯",
                "basic_information": f"æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}",
                "characteristics": "",
                "character_summary": "",
                "biography": ""
            }
        }

# ä¿å­˜åˆ°Excelå‡½æ•°
def save_to_excel(characters: Dict[str, Dict[str, Any]], 
                  output_path: str = os.path.join(OUTPUT_DIR, "character.xlsx")) -> None:
    """æ‰¹é‡ä¿å­˜äººç‰©ä¿¡æ¯åˆ°Excel"""
    if not characters:
        print("æ²¡æœ‰éœ€è¦ä¿å­˜çš„äººç‰©ä¿¡æ¯")
        return
    
    characters_list = list(characters.values())
    df = pd.DataFrame(characters_list)
    
    # åˆ—åæ˜ å°„ä¸æ’åº
    column_mapping = {
        "script_name": "å‰§æœ¬åç§°",
        "character_name": "è§’è‰²åç§°",
        "basic_information": "åŸºæœ¬ä¿¡æ¯",
        "characteristics": "è§’è‰²ç‰¹å¾",
        "biography": "äººç‰©å°ä¼ ",
        "character_summary": "äººç‰©æ‘˜è¦"
    }
    df = df.rename(columns=column_mapping)
    df.insert(0, "åºå·", range(1, len(df) + 1))
    desired_columns = ["åºå·", "å‰§æœ¬åç§°", "è§’è‰²åç§°", "åŸºæœ¬ä¿¡æ¯", "è§’è‰²ç‰¹å¾", "äººç‰©å°ä¼ ", "äººç‰©æ‘˜è¦"]
    df = df[desired_columns]
    
    # ä¿å­˜æ–‡ä»¶
    try:
        if os.path.exists(output_path):
            existing_df = pd.read_excel(output_path, engine='openpyxl')
            combined_df = pd.concat([existing_df, df], ignore_index=True)
            combined_df.to_excel(output_path, index=False, engine='openpyxl')
            print(f"æˆåŠŸè¿½åŠ æ•°æ®ï¼Œå½“å‰æ€»è®°å½•æ•°: {len(combined_df)}")
        else:
            df.to_excel(output_path, index=False, engine='openpyxl')
            print(f"æˆåŠŸåˆ›å»ºæ–‡ä»¶ï¼Œåˆå§‹è®°å½•æ•°: {len(df)}")
    except Exception as e:
        print(f"ä¿å­˜Excelå¤±è´¥: {e}ï¼Œå°è¯•ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶")
        temp_path = f"{output_path}.temp.xlsx"
        df.to_excel(temp_path, index=False, engine='openpyxl')
        print(f"ä¸´æ—¶æ–‡ä»¶ä¿å­˜æˆåŠŸ: {temp_path}")

# æ‰¹é‡å¤„ç†å…¥å£å‡½æ•°
def process_batch_scripts():
    """å¤„ç†ç›®å½•ä¸‹æ‰€æœ‰å‰§æœ¬æ–‡ä»¶"""
    script_files = [f for f in os.listdir(SCRIPT_DIR) 
                   if os.path.isfile(os.path.join(SCRIPT_DIR, f)) 
                   and f.lower().endswith('.txt')]  # æ”¯æŒå¤§å°å†™æ•æ„Ÿ
    
    if not script_files:
        return "ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°txtå‰§æœ¬æ–‡ä»¶", []
    
    all_characters = {}
    error_count = 0
    
    for file in script_files:
        file_path = os.path.join(SCRIPT_DIR, file)
        try:
            chars = asyncio.run(extract_character_information(PROMPT, file_path))
            all_characters.update(chars)
        except Exception as e:
            error_count += 1
            print(f"æ–‡ä»¶ {file} å¤„ç†å¤±è´¥: {str(e)}")
    
    # ä¿å­˜ç»“æœ
    save_to_excel(all_characters)
    
    # ç”ŸæˆçŠ¶æ€ä¿¡æ¯
    status = f"âœ… å¤„ç†å®Œæˆ\næ–‡ä»¶æ€»æ•°: {len(script_files)}\næˆåŠŸæå–è§’è‰²æ•°: {len(all_characters) - error_count}\né”™è¯¯æ–‡ä»¶æ•°: {error_count}"
    if error_count > 0:
        status += "\nâš ï¸ é”™è¯¯è¯¦æƒ…è¯·æŸ¥çœ‹æ§åˆ¶å°æ—¥å¿—"
    
    # ç”Ÿæˆé¢„è§ˆç»“æœï¼ˆé™åˆ¶2000å­—ï¼‰
    preview = "\n".join([
        f"å‰§æœ¬: {char['script_name']}\nè§’è‰²: {char['character_name']}\næ‘˜è¦: {char['character_summary'][:200]}\n---"
        for char in list(all_characters.values())[:20]  # æœ€å¤šæ˜¾ç¤ºå‰20ä¸ªè§’è‰²
    ])[:2000]  # é™åˆ¶æ€»é•¿åº¦
    
    return status, preview

# åˆ›å»ºGradioç•Œé¢
def create_interface():
    with gr.Blocks(title="æ‰¹é‡å‰§æœ¬äººç‰©åˆ†æç³»ç»Ÿ", css="style.css") as interface:
        gr.Markdown("# ğŸ“š å‰§æœ¬äººç‰©ä¿¡æ¯æ‰¹é‡æå–ç³»ç»Ÿ")
        gr.Markdown("è‡ªåŠ¨åˆ†æ `/opt/Filmdataset/demo/clean` ç›®å½•ä¸‹çš„æ‰€æœ‰TXTå‰§æœ¬æ–‡ä»¶")
        
        with gr.Column(scale=1, min_width=600):
            status_box = gr.Textbox(
                label="å¤„ç†çŠ¶æ€", 
                lines=3, 
                interactive=False, 
                placeholder="ç­‰å¾…å¤„ç†..."
            )
            result_box = gr.Textbox(
                label="æå–ç»“æœé¢„è§ˆ", 
                lines=10, 
                interactive=False, 
                placeholder="ç»“æœå°†æ˜¾ç¤ºåœ¨æ­¤å¤„"
            )
            process_btn = gr.Button(
                "å¼€å§‹æ‰¹é‡å¤„ç†", 
                variant="primary", 
                size="lg", 
                icon="fa-solid fa-play"
            )
        
        # ç»‘å®šå¤„ç†å‡½æ•°
        process_btn.click(
            fn=process_batch_scripts,
            outputs=[status_box, result_box]
        )
    
    return interface

if __name__ == "__main__":
    interface = create_interface()
    interface.launch(server_port=7860, share=False)