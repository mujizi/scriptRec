import os
import json
import gradio as gr
import pandas as pd
from typing import List, Dict, Any, Optional
import asyncio
from dotenv import load_dotenv
from openai import AsyncAzureOpenAI

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv('/opt/rag_milvus_kb_project/.env')

# ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
AZURE_OPENAI_API_KEY = os.getenv('AZURE_OPENAI_API_KEY')
AZURE_OPENAI_ENDPOINT = os.getenv('AZURE_OPENAI_ENDPOINT')
API_VERSION = os.getenv('API_VERSION', '2025-01-01-preview')

if not all([AZURE_OPENAI_API_KEY, AZURE_OPENAI_ENDPOINT]):
    raise ValueError("Missing required environment variables: AZURE_OPENAI_API_KEY or AZURE_OPENAI_ENDPOINT")

# ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨
os.makedirs("/opt/Filmdataset/demo/script_3000/batch_009", exist_ok=True)
os.makedirs("/opt/Filmdataset/demo/juben_cn/batch_009", exist_ok=True)

# ä¿®æ­£åçš„æç¤ºè¯ï¼ˆä¿®å¤å­—æ®µé‡å¤é—®é¢˜ï¼‰
PROMPT = """
- systemæç¤ºè¯
    - ä½ æ˜¯ä¸€ä½ä¸“ä¸šç”µå½±ç¼–å‰§ã€‚
- æ ¹æ®æ‰€ç»™å‰§æœ¬ï¼Œåˆ†åˆ«æ€»ç»“å‰§æœ¬ä»¥ä¸‹ä¿¡æ¯ï¼š
    - å‰§æœ¬ä¸»é¢˜(script_theme)ï¼š
        - æ€»ç»“è¯¥ç”µå½±å‰§æœ¬çš„ä¸»é¢˜ã€‚è¯´æ˜ï¼šä¸»é¢˜é€šå¸¸æ˜¯æŒ‡å½±ç‰‡æ¢è®¨çš„æ ¸å¿ƒæ¦‚å¿µæˆ–é“å¾·ä¿¡æ¯ã€‚å½±ç‰‡çš„ä¸»é¢˜å¯ä»¥æœ‰å¤šç§ï¼Œé€šå¸¸å…·æœ‰æ™®éæ€§è´¨ï¼Œæ¶‰åŠäººç±»å…±é€šçš„ç»éªŒå’Œä»·å€¼è§‚ã€‚
    - å‰§æœ¬é¢˜æ(script_genre)ï¼š
        - æ€»ç»“è¯¥ç”µå½±å‰§æœ¬çš„é¢˜æã€‚è¯´æ˜ï¼šé¢˜ææ˜¯æŒ‡ç”µå½±å‰§æœ¬è®¨è®ºçš„æ ¸å¿ƒå†…å®¹ã€ä¸»æ—¨æˆ–æ¢ç©¶çš„é¢†åŸŸï¼Œå®ƒå½¢æˆäº†å½±ç‰‡è®²è¿°æ•…äº‹çš„åŸºç¡€èƒŒæ™¯ï¼Œå®ƒé€šå¸¸å›´ç»•äººç±»ç»éªŒçš„æŸä¸ªæ–¹é¢ã€‚
    - å‰§æœ¬ç±»å‹(script_type)ï¼š
        - æ€»ç»“è¯¥ç”µå½±å‰§æœ¬çš„ç±»å‹ã€‚è¯´æ˜ï¼šç±»å‹æ˜¯æ ¹æ®ç”µå½±çš„é£æ ¼ã€å™è¿°æ–¹å¼å’Œè§‚ä¼—é¢„æœŸæ¥åˆ†ç±»çš„ã€‚
    - å‰§æœ¬äºšç±»å‹(script_subtypes)ï¼š  
        - æ€»ç»“è¯¥ç”µå½±å‰§æœ¬çš„äºšç±»å‹ã€‚äºšç±»å‹æ˜¯æŒ‡åœ¨ç”µå½±ä¸»ç±»å‹ä¹‹ä¸‹ï¼Œæ ¹æ®æ›´ç»†å¾®çš„é£æ ¼ã€ä¸»é¢˜æˆ–å†…å®¹ç‰¹å¾è¿›è¡Œçš„è¿›ä¸€æ­¥åˆ†ç±»ã€‚
    - å‰§æœ¬èƒŒæ™¯è®¾ç½®(script_background)ï¼š
        - æ€»ç»“è¯¥ç”µå½±å‰§æœ¬çš„èƒŒæ™¯è®¾ç½®ï¼Œ200å­—ä»¥å†…ï¼ŒåŒ…æ‹¬æ•…äº‹ä¸–ç•Œè®¾å®šã€æ•…äº‹å‘ç”Ÿçš„åœ°ç‚¹å’Œç©ºé—´ã€æ—¶ä»£èƒŒæ™¯ã€æ•…äº‹æ—¶é—´è·¨åº¦å’Œç¤¾ä¼šç¯å¢ƒç­‰ã€‚
    - å‰§æœ¬æ•…äº‹æ¢—æ¦‚(script_synopsis)ï¼š
        -æ€»ç»“è¯¥ç”µå½±å‰§æœ¬çš„æ•…äº‹æ¢—æ¦‚ï¼Œ300å­—å·¦å³ï¼Œé€šå¸¸åŒ…å«ä¸»è¦è§’è‰²ã€åŠ¨æœºç›®æ ‡ã€å¯¹æŠ—æ€§åŠ›é‡ã€æ ¸å¿ƒå†²çªã€ä¸»è¦æƒ…èŠ‚(å¼€ç«¯ã€å‘å±•ä¸ç»“å±€)ç­‰å†…å®¹
    - å‰§æœ¬ç»“æ„(script_structure)ï¼š 
        - æ€»ç»“è¯¥å‰§æœ¬çš„æ•…äº‹ç»“æ„ï¼Œå¸¸è§çš„å‰§æœ¬ç»“æ„åŒ…å«ä¸‰å¹•ç»“æ„ã€äº”å¹•ç»“æ„ã€è‹±é›„ä¹‹æ—…ç»“æ„ã€æ•‘çŒ«å’ªç»“æ„ç­‰ã€‚å¹¶ç®€å•è¾“å‡ºè¯¥ç”µå½±å‰§æœ¬çš„ç»“æ„å¤§çº²ã€‚
   - å‰§æœ¬æ‘˜è¦(script_summary)ï¼š
        - ä»¥ä¸€å¥è¯æè¿°ï¼Œå­—æ•°å°äº30ä¸ªå­—ã€‚ä¾‹å¦‚ï¼š1.è®¨è®ºçˆ±æƒ…ä¸å©šå§»ä¸­ä¿¡ä»»ä¸èƒŒå›çš„å®¶åº­å‰§ã€‚2.å¿ è¯šä¸èƒŒå›ï¼Œå§åº•ä¸è­¦å¯Ÿçš„è­¦åŒªåŠ¨ä½œç‰‡ã€‚3.å…³äºäººç±»ä¸äººå·¥æ™ºèƒ½ä¹‹é—´çš„ä¼¦ç†å’Œé“å¾·å†²çªçš„ç§‘å¹»ç‰‡ã€‚
   - è¾“å‡ºæ ·ä¾‹
    {
        "script_name":"XXX",
        "script_theme":"XXX",
        "script_genre":"XXX",
        "script_type":"XXX",
        "script_subtypes":"XXX",
        "script_background":"XXX",
        "script_synopsis":"XXX",
        "script_structure":"XXX",
        "script_summary":"XXX"
    }
- è¾“å‡ºè¦æ±‚
   - 1ã€ä¸¥æ ¼æŒ‰ç…§è¾“å‡ºæ ·ä¾‹çš„JSONæ ¼å¼è¾“å‡ºï¼Œä¸è¦æ–°å¢æˆ–ä¿®æ”¹å­—æ®µã€‚
"""

async def async_model_gpt4o_infer(instruct_text: str, raw_text: str) -> str:
    """è°ƒç”¨Azure OpenAIçš„gpt-4o-miniæ¨¡å‹è¿›è¡Œæ¨ç†ï¼Œç¡®ä¿è¿”å›JSONæ ¼å¼"""
    text = f"{instruct_text} {raw_text}"
    print(f"Processing text block of length: {len(raw_text)}")
    client = AsyncAzureOpenAI(
        azure_endpoint=AZURE_OPENAI_ENDPOINT,
        api_key=AZURE_OPENAI_API_KEY,
        api_version=API_VERSION
    )
    response = await client.chat.completions.create(
        # model="gpt-4o-mini",
        model="gpt-4.1",
        messages=[
            {"role": "user", "content": text},
        ],
        temperature=1,
        top_p=0.7,
        response_format={"type": "json_object"}  # å¼ºåˆ¶è¦æ±‚JSONæ ¼å¼å“åº”
    )
    return response.choices[0].message.content

async def extract_script_information(prompt: str, script_path: str) -> Dict[str, Any]:
    """æå–å‰§æœ¬ä¿¡æ¯"""
    try:
        with open(script_path, 'r', encoding='utf-8') as file:
            script_content = file.read()
        
        script_name = os.path.basename(script_path).replace(".txt", "")
        result_text = await async_model_gpt4o_infer(prompt, script_content)
        
        try:
            result_data = json.loads(result_text)
            result_data["script_name"] = script_name  # ç¡®ä¿åŒ…å«å‰§æœ¬å
            return result_data
        except json.JSONDecodeError as e:
            print(f"è§£æJSONå¤±è´¥: {e}")
            print(f"æ¨¡å‹è¿”å›å†…å®¹: {result_text}")
            return {
                "script_name": script_name,
                "error": f"JSONè§£æå¤±è´¥: {str(e)}"
            }
            
    except Exception as e:
        print(f"æå–å‰§æœ¬ä¿¡æ¯æ—¶å‡ºé”™: {e}")
        script_name = os.path.basename(script_path).replace(".txt", "")
        return {
            "script_name": script_name,
            "error": f"å¤„ç†å¤±è´¥: {str(e)}"
        }

def save_to_excel(script_data_list: List[Dict[str, Any]], output_path: str = "/opt/Filmdataset/demo/script_3000/batch009/script_batch009.xlsx") -> None:
    """å°†å‰§æœ¬ä¿¡æ¯ä¿å­˜åˆ°Excelï¼ˆæ˜ç¡®æŒ‡å®šopenpyxlå¼•æ“ï¼‰"""
    try:
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        columns = [
            "script_name", "script_theme", "script_genre", "script_type",
            "script_subtypes", "script_background", "script_synopsis",
            "script_structure" ,"script_summary"
        ]
        df = pd.DataFrame(script_data_list, columns=columns)
        
        # ä½¿ç”¨openpyxlå¼•æ“ï¼ˆéœ€æå‰å®‰è£…ï¼‰
        engine = "openpyxl"  
        
        # å¤„ç†æ–‡ä»¶å­˜åœ¨æƒ…å†µ
        if os.path.exists(output_path):
            try:
                existing_df = pd.read_excel(output_path, engine=engine)
                combined_df = pd.concat([existing_df, df], ignore_index=True)
            except Exception as e:
                print(f"è¯»å–ç°æœ‰Excelæ–‡ä»¶æ—¶å‡ºé”™: {e}")
                raise
        else:
            combined_df = df
        
        # ä¿å­˜ä¸ºxlsxæ–‡ä»¶
        try:
            combined_df.to_excel(output_path, index=False, engine=engine)
            print(f"æˆåŠŸä¿å­˜åˆ°Excelï¼Œè·¯å¾„ï¼š{output_path}ï¼Œè®°å½•æ•°ï¼š{len(combined_df)}")
        except Exception as e:
            print(f"ä¿å­˜åˆ°Excelæ–‡ä»¶æ—¶å‡ºé”™: {e}")
            raise
        
    except Exception as e:
        print(f"ä¿å­˜å¤±è´¥ï¼š{str(e)}")
        if "openpyxl" in str(e):
            print("æç¤ºï¼šè¯·å®‰è£…openpyxlåº“ï¼špip install openpyxl")
        raise

def print_script_info(script_data: Dict[str, Any]) -> None:
    """æ‰“å°å‰§æœ¬ä¿¡æ¯"""
    print("\n=== å‰§æœ¬ä¿¡æ¯ ===")
    print(json.dumps(script_data, ensure_ascii=False, indent=2))

def get_script_files():
    """è·å–å‰§æœ¬æ–‡ä»¶åˆ—è¡¨"""
    script_dir = "/opt/Filmdataset/demo/juben_cn/batch_009"
    return [f for f in os.listdir(script_dir) if f.endswith('.txt')]

def create_interface():
    """åˆ›å»ºGradioç•Œé¢"""
    def process_scripts():
        script_files = get_script_files()
        if not script_files:
            return "è¯·ä¸Šä¼ txtå‰§æœ¬åˆ°/opt/Filmdataset/demo/juben_cn/batch_009", []
        
        all_script_data = []
        for script_name in script_files:
            script_path = os.path.join("/opt/Filmdataset/demo/juben_cn/batch_009", script_name)
            if not os.path.exists(script_path):
                print(f"é”™è¯¯: æ–‡ä»¶ '{script_name}' ä¸å­˜åœ¨")
                continue
            
            try:
                script_data = asyncio.run(extract_script_information(PROMPT, script_path))
                all_script_data.append(script_data)
                print_script_info(script_data)
            except Exception as e:
                print(f"å¤„ç†æ–‡ä»¶ '{script_name}' å¤±è´¥: {str(e)}")
        
        if all_script_data:
            save_to_excel(all_script_data)
        
        # æ„å»ºæ˜¾ç¤ºå†…å®¹
        display_text = []
        for script_data in all_script_data:
            for key, value in script_data.items():
                if key == "error":
                    display_text.append(f"é”™è¯¯: {value}")
                else:
                    display_text.append(f"{key.capitalize()}: {value}")
            display_text.append("-" * 50)
        
        return "å¤„ç†æˆåŠŸ", "\n".join(display_text)
    
    def refresh_file_list():
        script_files = get_script_files()
        if not script_files:
            return gr.Dropdown.update(choices=[], value=None), gr.Markdown("è¯·ä¸Šä¼ txtå‰§æœ¬åˆ°/opt/Filmdataset/demo/juben_cn/batch_009")
        return gr.Dropdown.update(choices=script_files, value=script_files[0]), gr.Markdown("")
    
    script_files = get_script_files()
    
    with gr.Blocks(title="å‰§æœ¬ä¿¡æ¯æå–ç³»ç»Ÿ") as interface:
        gr.Markdown("# ç”µå½±å‰§æœ¬ä¿¡æ¯æå–ç³»ç»Ÿ")
        
        with gr.Row():
            with gr.Column(scale=1):
                process_btn = gr.Button("æå–æ‰€æœ‰å‰§æœ¬ä¿¡æ¯", variant="primary")
                refresh_btn = gr.Button("ğŸ”„ åˆ·æ–°æ–‡ä»¶åˆ—è¡¨", variant="secondary")
            
            with gr.Column(scale=2):
                status_output = gr.Textbox(label="å¤„ç†çŠ¶æ€", interactive=False)
                info_output = gr.Textbox(label="æå–ç»“æœ", lines=15, interactive=False)
        
        process_btn.click(
            fn=process_scripts,
            inputs=[],
            outputs=[status_output, info_output]
        )
        
        refresh_btn.click(
            fn=refresh_file_list,
            inputs=[],
            outputs=[status_output]
        )
        
        if not script_files:
            gr.Markdown("æç¤ºï¼šè¯·å°†txtæ ¼å¼å‰§æœ¬ä¸Šä¼ åˆ° `/opt/Filmdataset/demo/juben_cn/batch_009` ç›®å½•")
    
    return interface

if __name__ == "__main__":
    interface = create_interface()
    interface.launch(server_name="0.0.0.0", server_port=7861)