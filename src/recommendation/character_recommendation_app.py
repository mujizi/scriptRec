import os
import sys
from dotenv import load_dotenv
import asyncio
import time
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
import numpy as np
import jieba
import re
from concurrent.futures import ThreadPoolExecutor, as_completed

load_dotenv()

# ä»ç¯å¢ƒå˜é‡è·å–å¹¶è®¾ç½® PYTHONPATH
pythonpath = os.getenv("PYTHONPATH")
if pythonpath and pythonpath not in sys.path:
    sys.path.insert(0, pythonpath)

print(os.getenv("MILVUS_URI"))
print(os.getenv("PYTHONPATH"))

import gradio as gr
from pymilvus import MilvusClient
from src.utils.llm import embedding_func
import numpy as np
import uuid
import os

# æ£€ç´¢ç­–ç•¥æšä¸¾
class SearchStrategy(Enum):
    DENSE_VECTOR = "dense_vector"
    BM25_SPARSE = "bm25_sparse"
    HYBRID = "hybrid"
    SEMANTIC_CHUNK = "semantic_chunk"
    MULTI_FIELD = "multi_field"
    ENSEMBLE = "ensemble"

@dataclass
class SearchResult:
    id: str
    character_name: str
    basic_information: str
    characteristics: str
    biography: str
    character_summary: str
    script_name: str
    similarity_score: float
    search_strategy: SearchStrategy
    confidence: float = 0.0

# è¿æ¥åˆ°Milvusæ•°æ®åº“ï¼ˆå‡è®¾äººç‰©é›†åˆåä¸ºcharacter_analysisï¼‰
db_name = "kb"
client = MilvusClient(uri="http://10.1.15.222:19530", db_name=db_name)
collection_name = "character"  # äººç‰©é›†åˆå
SIMILARITY_THRESHOLD = 0.4  # ç›¸ä¼¼åº¦é˜ˆå€¼

# å°è¯•åŠ è½½BM25æ¨¡å‹
bm25_model = None
try:
    from src.utils.bq_bm25 import load_bm25_ef
    bm25_model_path = os.path.join(os.path.dirname(__file__), "../utils/bm25_character_model.pkl")
    if os.path.exists(bm25_model_path):
        bm25_model = load_bm25_ef(bm25_model_path)
        print("BM25æ¨¡å‹åŠ è½½æˆåŠŸ")
except Exception as e:
    print(f"BM25æ¨¡å‹åŠ è½½å¤±è´¥: {e}")

def preprocess_query(query: str) -> str:
    """æŸ¥è¯¢é¢„å¤„ç†"""
    # å»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—
    query = re.sub(r'[^\w\s\u4e00-\u9fff]', '', query)
    # åˆ†è¯å¤„ç†
    words = jieba.lcut(query)
    return ' '.join(words)

def vector_query(client, collection_name, text, top_k=5):
    """åŸå§‹ç¨ å¯†å‘é‡æ£€ç´¢"""
    try:
        if not client.has_collection(collection_name):
            print(f"Error: Collection '{collection_name}' does not exist.")
            return None
        emb = embedding_func([text])
    except Exception as e:
        print(f"Error generating embedding: {e}")
        return None

    try:
        search_params = {
            "metric_type": "COSINE",
            "nprobe": 128,
        }

        print(f"Searching characters in '{collection_name}'...")
        search_res = client.search(
            collection_name=collection_name,
            data=emb,
            search_params=search_params,
            limit=top_k,
            anns_field="dense_vector",
            # åŒ¹é…äººç‰©æ•°æ®ç»“æ„å­—æ®µ
            output_fields=["id", "character_name", "basic_information", "characteristics", 
                          "biography", "character_summary", "script_name"],
        )

        results = []
        for hit in search_res[0]:
            similarity_score = hit["distance"]
            if similarity_score < SIMILARITY_THRESHOLD:
                continue
            
            entity = hit["entity"]
            results.append({
                "id": entity["id"],
                "character_name": entity["character_name"],
                "basic_information": entity["basic_information"],
                "characteristics": entity["characteristics"],
                "biography": entity["biography"],
                "character_summary": entity["character_summary"],
                "script_name": entity["script_name"],
                "similarity_score": similarity_score
            })
        print(f"Found {len(results)} matching characters.")
        return results

    except Exception as e:
        print(f"Search error: {e}")
        return []

def bm25_sparse_search(text, top_k=5):
    """BM25ç¨€ç–å‘é‡æ£€ç´¢"""
    if not bm25_model:
        return []
    
    try:
        processed_query = preprocess_query(text)
        query_embeddings = bm25_model.encode_queries([processed_query])
        query_row = query_embeddings._getrow(0)
        
        if query_row.indices.size == 0 or query_row.data.size == 0:
            return []
        
        query_sparse_vector = dict(zip(query_row.indices.astype(int), query_row.data.astype(float)))
        
        search_params = {
            "metric_type": "IP",
        }
        
        search_res = client.search(
            collection_name=collection_name,
            data=[query_sparse_vector],
            search_params=search_params,
            limit=top_k,
            anns_field="bm25_vector",
            output_fields=["id", "character_name", "basic_information", "characteristics", 
                          "biography", "character_summary", "script_name"],
        )
        
        results = []
        for hit in search_res[0]:
            similarity_score = hit["distance"]
            if similarity_score < SIMILARITY_THRESHOLD:
                continue
            
            entity = hit["entity"]
            results.append({
                "id": entity["id"],
                "character_name": entity["character_name"],
                "basic_information": entity["basic_information"],
                "characteristics": entity["characteristics"],
                "biography": entity["biography"],
                "character_summary": entity["character_summary"],
                "script_name": entity["script_name"],
                "similarity_score": similarity_score
            })
        
        return results
        
    except Exception as e:
        print(f"BM25 sparse search error: {e}")
        return []

def semantic_chunk_search(text, top_k=5):
    """è¯­ä¹‰åˆ†å—æ£€ç´¢ - å°†æŸ¥è¯¢åˆ†è§£ä¸ºå¤šä¸ªè¯­ä¹‰ç‰‡æ®µ"""
    try:
        # å°†æŸ¥è¯¢åˆ†è§£ä¸ºå¤šä¸ªè¯­ä¹‰ç‰‡æ®µ
        chunks = split_query_into_chunks(text)
        all_results = []
        
        for chunk in chunks:
            chunk_results = vector_query(client, collection_name, chunk, top_k=top_k//len(chunks))
            if chunk_results:
                all_results.extend(chunk_results)
        
        # å»é‡å¹¶é‡æ–°æ’åº
        unique_results = deduplicate_results(all_results)
        return sorted(unique_results, key=lambda x: x["similarity_score"], reverse=True)[:top_k]
        
    except Exception as e:
        print(f"Semantic chunk search error: {e}")
        return []

def split_query_into_chunks(query: str) -> List[str]:
    """å°†æŸ¥è¯¢åˆ†è§£ä¸ºè¯­ä¹‰ç‰‡æ®µ"""
    # ç®€å•çš„åŸºäºæ ‡ç‚¹ç¬¦å·çš„åˆ†å‰²
    chunks = re.split(r'[ï¼Œã€‚ï¼ï¼Ÿã€ï¼›]', query)
    chunks = [chunk.strip() for chunk in chunks if chunk.strip()]
    
    # å¦‚æœåªæœ‰ä¸€ä¸ªç‰‡æ®µï¼Œå°è¯•æŒ‰å…³é”®è¯åˆ†å‰²
    if len(chunks) <= 1:
        words = jieba.lcut(query)
        if len(words) > 3:
            mid = len(words) // 2
            chunks = [' '.join(words[:mid]), ' '.join(words[mid:])]
    
    return chunks[:3]  # æœ€å¤š3ä¸ªç‰‡æ®µ

def multi_field_search(text, top_k=5):
    """å¤šå­—æ®µæ£€ç´¢ - åœ¨ä¸åŒå­—æ®µä¸Šåˆ†åˆ«æœç´¢"""
    try:
        # åœ¨è§’è‰²åç§°å­—æ®µæœç´¢
        name_results = search_in_field(text, "character_name", top_k)
        
        # åœ¨ç‰¹å¾å­—æ®µæœç´¢
        characteristic_results = search_in_field(text, "characteristics", top_k)
        
        # åœ¨ä¼ è®°å­—æ®µæœç´¢
        biography_results = search_in_field(text, "biography", top_k)
        
        # åˆå¹¶ç»“æœ
        all_results = name_results + characteristic_results + biography_results
        unique_results = deduplicate_results(all_results)
        
        return sorted(unique_results, key=lambda x: x["similarity_score"], reverse=True)[:top_k]
        
    except Exception as e:
        print(f"Multi-field search error: {e}")
        return []

def search_in_field(text, field_name, top_k):
    """åœ¨æŒ‡å®šå­—æ®µä¸­æœç´¢"""
    try:
        emb = embedding_func([text])
        
        search_params = {
            "metric_type": "COSINE",
            "nprobe": 128,
        }
        
        search_res = client.search(
            collection_name=collection_name,
            data=emb,
            search_params=search_params,
            limit=top_k,
            anns_field="dense_vector",
            output_fields=["id", "character_name", "basic_information", "characteristics", 
                          "biography", "character_summary", "script_name"],
        )
        
        results = []
        for hit in search_res[0]:
            similarity_score = hit["distance"]
            if similarity_score < SIMILARITY_THRESHOLD:
                continue
            
            entity = hit["entity"]
            results.append({
                "id": entity["id"],
                "character_name": entity["character_name"],
                "basic_information": entity["basic_information"],
                "characteristics": entity["characteristics"],
                "biography": entity["biography"],
                "character_summary": entity["character_summary"],
                "script_name": entity["script_name"],
                "similarity_score": similarity_score
            })
        
        return results
        
    except Exception as e:
        print(f"Field search error for {field_name}: {e}")
        return []

def hybrid_search(text, top_k=5, dense_weight=0.7):
    """æ··åˆæ£€ç´¢ - ç»“åˆç¨ å¯†å‘é‡å’ŒBM25"""
    try:
        # å¹¶è¡Œæ‰§è¡Œä¸¤ç§æœç´¢
        with ThreadPoolExecutor(max_workers=2) as executor:
            dense_future = executor.submit(vector_query, client, collection_name, text, top_k)
            bm25_future = executor.submit(bm25_sparse_search, text, top_k)
            
            dense_results = dense_future.result() or []
            bm25_results = bm25_future.result() or []
        
        # åˆå¹¶ç»“æœ
        combined_results = {}
        
        # å¤„ç†ç¨ å¯†å‘é‡ç»“æœ
        for result in dense_results:
            combined_results[result["id"]] = {
                'result': result,
                'dense_score': result["similarity_score"],
                'bm25_score': 0.0
            }
        
        # å¤„ç†BM25ç»“æœ
        for result in bm25_results:
            if result["id"] in combined_results:
                combined_results[result["id"]]['bm25_score'] = result["similarity_score"]
            else:
                combined_results[result["id"]] = {
                    'result': result,
                    'dense_score': 0.0,
                    'bm25_score': result["similarity_score"]
                }
        
        # è®¡ç®—æ··åˆåˆ†æ•°
        final_results = []
        for item in combined_results.values():
            hybrid_score = (dense_weight * item['dense_score'] + 
                          (1 - dense_weight) * item['bm25_score'])
            
            result = item['result']
            result["similarity_score"] = hybrid_score
            final_results.append(result)
        
        return sorted(final_results, key=lambda x: x["similarity_score"], reverse=True)[:top_k]
        
    except Exception as e:
        print(f"Hybrid search error: {e}")
        return []

def ensemble_search(text, top_k=5):
    """é›†æˆæ£€ç´¢ - ä½¿ç”¨å¤šç§ç­–ç•¥å¹¶æŠ•ç¥¨"""
    try:
        # æ‰§è¡Œæ‰€æœ‰æœç´¢ç­–ç•¥
        strategies = [
            lambda t, k: vector_query(client, collection_name, t, k),
            bm25_sparse_search,
            semantic_chunk_search,
            multi_field_search
        ]
        
        all_results = []
        with ThreadPoolExecutor(max_workers=len(strategies)) as executor:
            futures = [executor.submit(strategy, text, top_k) for strategy in strategies]
            
            for future in as_completed(futures):
                try:
                    results = future.result() or []
                    all_results.extend(results)
                except Exception as e:
                    print(f"Strategy execution error: {e}")
        
        # æŠ•ç¥¨æœºåˆ¶
        vote_counts = {}
        score_sums = {}
        
        for result in all_results:
            if result["id"] not in vote_counts:
                vote_counts[result["id"]] = 0
                score_sums[result["id"]] = 0.0
            
            vote_counts[result["id"]] += 1
            score_sums[result["id"]] += result["similarity_score"]
        
        # è®¡ç®—æœ€ç»ˆåˆ†æ•°
        final_results = []
        for result_id, vote_count in vote_counts.items():
            avg_score = score_sums[result_id] / vote_count
            # æŠ•ç¥¨æƒé‡
            final_score = avg_score * (1 + 0.1 * vote_count)
            
            # æ‰¾åˆ°å¯¹åº”çš„ç»“æœå¯¹è±¡
            for result in all_results:
                if result["id"] == result_id:
                    result["similarity_score"] = final_score
                    result["confidence"] = vote_count / len(strategies)
                    final_results.append(result)
                    break
        
        return sorted(final_results, key=lambda x: x["similarity_score"], reverse=True)[:top_k]
        
    except Exception as e:
        print(f"Ensemble search error: {e}")
        return []

def deduplicate_results(results):
    """å»é‡ç»“æœ"""
    seen_ids = set()
    unique_results = []
    
    for result in results:
        if result["id"] not in seen_ids:
            seen_ids.add(result["id"])
            unique_results.append(result)
    
    return unique_results

def build_search_ui():
    def search(query, strategy_name, top_k):
        if not query.strip():
            return "è¯·è¾“å…¥äººç‰©ç‰¹å¾æè¿°"
        
        try:
            top_k = int(top_k)
            start_time = time.time()
            
            if strategy_name == "dense_vector":
                results = vector_query(client, collection_name, query, top_k)
            elif strategy_name == "bm25_sparse":
                results = bm25_sparse_search(query, top_k)
            elif strategy_name == "hybrid":
                results = hybrid_search(query, top_k)
            elif strategy_name == "semantic_chunk":
                results = semantic_chunk_search(query, top_k)
            elif strategy_name == "multi_field":
                results = multi_field_search(query, top_k)
            elif strategy_name == "ensemble":
                results = ensemble_search(query, top_k)
            else:
                results = vector_query(client, collection_name, query, top_k)
            
            end_time = time.time()
            
            if not results:
                return f"æœªæ‰¾åˆ°ç›¸å…³äººç‰© (è€—æ—¶: {end_time - start_time:.2f}s)"
            
            # æ ¼å¼åŒ–ç»“æœä¸ºå­—ç¬¦ä¸²
            formatted_results = []
            strategy_names = {
                "dense_vector": "ç¨ å¯†å‘é‡æ£€ç´¢",
                "bm25_sparse": "BM25ç¨€ç–å‘é‡æ£€ç´¢", 
                "hybrid": "æ··åˆæ£€ç´¢",
                "semantic_chunk": "è¯­ä¹‰åˆ†å—æ£€ç´¢",
                "multi_field": "å¤šå­—æ®µæ£€ç´¢",
                "ensemble": "é›†æˆæ£€ç´¢"
            }
            
            strategy_name_display = strategy_names.get(strategy_name, "æœªçŸ¥ç­–ç•¥")
            
            for i, result in enumerate(results, 1):
                confidence_text = f" (ç½®ä¿¡åº¦: {result.get('confidence', 0):.2f})" if result.get('confidence', 0) > 0 else ""
                character_info = [
                    f"**{i}. {result['character_name']}** (ç›¸ä¼¼åº¦: {result['similarity_score']:.3f}){confidence_text}",
                    f"**åŸºæœ¬ä¿¡æ¯**: {result['basic_information']}",
                    f"**äººç‰©ç‰¹å¾**: {result['characteristics']}",
                    f"**æ‰€å±å‰§æœ¬**: {result['script_name']}",
                    f"**äººç‰©ä¼ è®°**: {result['biography']}",
                    f"**äººç‰©æ€»ç»“**: {result['character_summary']}"
                ]
                formatted_results.append("\n".join(character_info))
            
            # ç”¨"â€”â€”â€”â€”â€”â€”"åˆ†å‰²ä¸åŒå…ƒç´ 
            result_text = f"**æ£€ç´¢ç­–ç•¥**: {strategy_name_display} (è€—æ—¶: {end_time - start_time:.2f}s)\n\n"
            result_text += "\n\nâ€”â€”â€”â€”â€”â€”\n\n".join(formatted_results)
            return result_text
            
        except Exception as e:
            return f"æœç´¢å‡ºé”™: {str(e)}"

    def compare_strategies(query, top_k):
        """æ¯”è¾ƒä¸åŒæ£€ç´¢ç­–ç•¥çš„æ•ˆæœ"""
        if not query.strip():
            return "è¯·è¾“å…¥äººç‰©ç‰¹å¾æè¿°"
        
        comparison_results = []
        strategies = [
            ("ç¨ å¯†å‘é‡æ£€ç´¢", "dense_vector"),
            ("BM25ç¨€ç–å‘é‡æ£€ç´¢", "bm25_sparse"),
            ("æ··åˆæ£€ç´¢", "hybrid"),
            ("è¯­ä¹‰åˆ†å—æ£€ç´¢", "semantic_chunk"),
            ("å¤šå­—æ®µæ£€ç´¢", "multi_field"),
            ("é›†æˆæ£€ç´¢", "ensemble")
        ]
        
        for strategy_name, strategy_key in strategies:
            try:
                start_time = time.time()
                results = search(query, strategy_key, top_k)
                end_time = time.time()
                
                comparison_results.append(f"## {strategy_name}")
                comparison_results.append(f"**æ‰§è¡Œæ—¶é—´**: {end_time - start_time:.2f}ç§’")
                comparison_results.append(f"**ç»“æœ**: {results}")
                comparison_results.append("")
                
            except Exception as e:
                comparison_results.append(f"## {strategy_name}")
                comparison_results.append(f"**é”™è¯¯**: {str(e)}")
                comparison_results.append("")
        
        return "\n".join(comparison_results)

    with gr.Blocks(title="é«˜çº§äººç‰©æ¨èç³»ç»Ÿ", theme=gr.themes.Soft()) as demo:
        gr.HTML("""
        <style>
            .results-container {display:flex;flex-direction:column;gap:20px;}
            .result-card {background:#fff;border-radius:12px;box-shadow:0 4px 20px rgba(0,0,0,0.08);overflow:hidden;transform:translateY(10px);opacity:0;animation:fadeInUp 0.5s forwards;transition:all 0.3s ease;}
            .result-card:hover {box-shadow:0 8px 30px rgba(0,0,0,0.12);transform:translateY(-2px);}
            @keyframes fadeInUp {to{transform:translateY(0);opacity:1;}}
            .card-header {background:#f8f9fa;padding:16px 20px;display:flex;justify-content:space-between;align-items:center;border-bottom:1px solid #e9ecef;}
            .character-name {margin:0;color:#212529;font-size:1.2rem;font-weight:600;}
            .similarity-badge {padding:4px 12px;border-radius:12px;color:white;font-size:0.9rem;font-weight:500;}
            .card-content {padding:20px;}
            .character-info {display:grid;grid-template-columns:1fr 1fr;gap:10px;margin-bottom:20px;}
            .info-row {display:flex;align-items:center;}
            .info-label {font-weight:500;color:#495057;min-width:80px;}
            .info-value {color:#212529;}
            .character-details h4 {color:#343a40;font-size:1rem;margin-top:15px;margin-bottom:5px;}
            .character-details p {color:#6c757d;margin:0 0 10px 0;line-height:1.5;}
            .gr-button {transition:all 0.3s ease;}
            .gr-button:hover {transform:translateY(-2px);}
            .gr-text-input:focus {box-shadow:0 0 0 3px rgba(13,110,253,0.25);}
            .strategy-info {background:#e3f2fd;padding:15px;border-radius:8px;margin:10px 0;}
        </style>
        """)
        
        gr.Markdown("""
        # <i class="fa-solid fa-user"></i> é«˜çº§äººç‰©æ¨èç³»ç»Ÿ
        æ”¯æŒå¤šç§æ£€ç´¢ç­–ç•¥çš„æ™ºèƒ½äººç‰©æ¨èç³»ç»Ÿ
        """)
        
        with gr.Row():
            with gr.Column(scale=3):
                with gr.Row():
                    query_input = gr.Textbox(
                        label="", 
                        placeholder="è¯·è¾“å…¥äººç‰©ç‰¹å¾æè¿°ï¼ˆå¦‚ï¼šå‹‡æ•¢çš„å¤ªç©ºæ¢é™©å®¶ã€å¤æ‚çš„åæ´¾è§’è‰²ï¼‰", 
                        lines=3,
                        container=False
                    )
                
                with gr.Row():
                    strategy_dropdown = gr.Dropdown(
                        choices=[
                            ("é›†æˆæ£€ç´¢ (æ¨è)", "ensemble"),
                            ("ç¨ å¯†å‘é‡æ£€ç´¢", "dense_vector"),
                            ("BM25ç¨€ç–å‘é‡æ£€ç´¢", "bm25_sparse"),
                            ("æ··åˆæ£€ç´¢", "hybrid"),
                            ("è¯­ä¹‰åˆ†å—æ£€ç´¢", "semantic_chunk"),
                            ("å¤šå­—æ®µæ£€ç´¢", "multi_field")
                        ],
                        value="ensemble",
                        label="æ£€ç´¢ç­–ç•¥"
                    )
                    top_k_slider = gr.Slider(
                        minimum=1,
                        maximum=20,
                        value=5,
                        step=1,
                        label="è¿”å›ç»“æœæ•°é‡"
                    )
                
                with gr.Row():
                    search_btn = gr.Button("ğŸ” æœç´¢", variant="primary")
                    compare_btn = gr.Button("âš–ï¸ ç­–ç•¥å¯¹æ¯”", variant="secondary")
                
            with gr.Column(scale=1):
                gr.Markdown("### <i class='fa-solid fa-info'></i> æ£€ç´¢ç­–ç•¥è¯´æ˜")
                gr.Markdown("""
                **é›†æˆæ£€ç´¢**: ç»¼åˆå¤šç§ç­–ç•¥ï¼ŒæŠ•ç¥¨é€‰å‡ºæœ€ä½³ç»“æœ
                
                **ç¨ å¯†å‘é‡**: åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦çš„æ·±åº¦æ£€ç´¢
                
                **BM25ç¨€ç–å‘é‡**: åŸºäºå…³é”®è¯åŒ¹é…çš„ç²¾ç¡®æ£€ç´¢
                
                **æ··åˆæ£€ç´¢**: ç»“åˆç¨ å¯†å‘é‡å’ŒBM25çš„ä¼˜åŠ¿
                
                **è¯­ä¹‰åˆ†å—**: å°†æŸ¥è¯¢åˆ†è§£ä¸ºå¤šä¸ªè¯­ä¹‰ç‰‡æ®µ
                
                **å¤šå­—æ®µ**: åœ¨ä¸åŒå­—æ®µä¸Šåˆ†åˆ«æœç´¢
                """)
        
        output = gr.HTML(label="æœç´¢ç»“æœ")
        
        with gr.Row():
            loading_status = gr.Markdown("", visible=False)
        
        # æœç´¢æŒ‰é’®äº‹ä»¶
        search_btn.click(
            fn=lambda x: (gr.update(visible=True), None, gr.update(visible=False)),
            inputs=query_input,
            outputs=[loading_status, output, search_btn]
        ).then(
            fn=search,
            inputs=[query_input, strategy_dropdown, top_k_slider],
            outputs=output
        ).then(
            fn=lambda: (gr.update(visible=False), gr.update(visible=True)),
            outputs=[loading_status, search_btn]
        )
        
        # ç­–ç•¥å¯¹æ¯”æŒ‰é’®äº‹ä»¶
        compare_btn.click(
            fn=lambda x: (gr.update(visible=True), None, gr.update(visible=False)),
            inputs=query_input,
            outputs=[loading_status, output, compare_btn]
        ).then(
            fn=compare_strategies,
            inputs=[query_input, top_k_slider],
            outputs=output
        ).then(
            fn=lambda: (gr.update(visible=False), gr.update(visible=True)),
            outputs=[loading_status, compare_btn]
        )
        
        gr.Examples(
            examples=[
                "å‹‡æ•¢åšéŸ§çš„è‹±é›„è§’è‰²",
                "æ€§æ ¼å‹‡æ•¢ï¼Œä¹äºåŠ©äººçš„è§’è‰²",
                "å¹½é»˜é£è¶£çš„ç§‘å¹»è§’è‰²",
                "ç™»å±±é˜Ÿé˜Ÿé•¿",
                "å¹´è½»ç¼‰æ¯’è­¦å¯Ÿ",
                "å¹½é»˜çš„è®°è€…",
                "å¤æ‚çš„åæ´¾è§’è‰²",
                "æ™ºæ…§å‹ä¾¦æ¢"
            ],
            inputs=query_input
        )

    return demo

if __name__ == "__main__":
    demo = build_search_ui()
    # demo.launch(server_name="0.0.0.0", server_port=7864)
    demo.launch(server_name="0.0.0.0", server_port=7868)